{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Workshop Primer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekgren/workshop/blob/main/Day1/Workshop_Primer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7Zmsd_GNJYa"
      },
      "source": [
        "# ML-primer\n",
        "\n",
        "I första lab-delen av workshoppen ska vi gå igenom ett exempel med bildigenkänning: MNIST.\n",
        "\n",
        "MNIST är ett dataset bestående av små bilder (28 x 28 pixlar) av siffror (0-9), med tillhörande sifferetikett (alltså siffran bilden föreställer). \n",
        "\n",
        "Datan består av 60.000 träningsexempel och 10.000 testexempel.\n",
        "\n",
        "Vi börjar med att importera pythonpaket som kommer användas.\n",
        "\n",
        "torch och torchvision är maskininlärningsbibliotek. \n",
        "\n",
        "*torch* är grundpaketet. Detta innehåller matematiska funnktioner, GPU-funktionalitet, ramverk för att definiera modeller, optimiera dessa m.m. och i synnerhet autograd: Ramverket som används för att beräkna gradienter.\n",
        "\n",
        "*torchvision* är ett tillägg till torch för just bildhantering.\n",
        "\n",
        "*matplotlib* är ett bibliotek för att visa diagram och bilder.\n",
        "\n",
        "*tqdm* är ett bibliotek som visar \"progress bars\".\n",
        "\n",
        "itertools är ett internt pythonbibliotek med hjälpfunktioner för iteratorer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUgEPhGYxkj8"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import tqdm\n",
        "import itertools\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK9SH_kfYWQe"
      },
      "source": [
        "# Optimering\n",
        "\n",
        "Vi börjar med att förklara grunden i hur neurala nätverk \"lär\" sig utifrån data.\n",
        "\n",
        "Nedan genererar vi påhittad data som har en linjär relation: $y = 2 + 4x + \\epsilon$, och visualiserar den. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qXyVNFN8w0Z"
      },
      "source": [
        "x = torch.linspace(0, 2, 100)\n",
        "true_a = 2\n",
        "true_b = -3\n",
        "y = true_a + true_b * x + torch.randn(100)\n",
        "\n",
        "plt.plot(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmKBVSMxY2At"
      },
      "source": [
        "Vi vill hitta en modell som givet $x$ kan predicera $y$. Alltså en parameteriserad mappning från $x$ till $y$.\n",
        "\n",
        "Låt denna mappning vara $f(x) = a + bx$. Våra parametrar är alltså $a$ och $b$.\n",
        "Vi initialiserar modellen till $a=0$ och $b=0$, och visualiserar den nedan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHBoCUQzbtYq"
      },
      "source": [
        "# Initialisera modellens parametrar \n",
        "# (och specificera att vi vill räkna ut deras gradienter)\n",
        "a = torch.torch.zeros((), requires_grad=True)\n",
        "b = torch.torch.zeros((), requires_grad=True)\n",
        "\n",
        "# predicera y\n",
        "def y_pred(x):\n",
        "  return a + x * b\n",
        "\n",
        "with torch.no_grad():\n",
        "  plt.plot(x, y)\n",
        "  plt.plot(x, y_pred(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZaW--gObxm_"
      },
      "source": [
        "Eftersom vi vill formulera detta som ett optimeringsproblem måste vi ha en \"loss\", eller ett fel, som ska återspegla hur korrekt vår model $f$ är.\n",
        "\n",
        "I detta fall kan vi låta vårt fel vara $\\mathbb{E}(f(x) - y)^2$, medelvärdet av kvadraten av skillnaden mellan vår predicerade $y$ ($f(x)$), och det sanna.\n",
        "Denna loss kallas vanligtvis MSE, eller Mean Squared Error, och är bland de vanligaste för regressionsproblem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-oKTrNWcCqG"
      },
      "source": [
        "def loss(x, y):\n",
        "  return (y_pred(x) - y).pow(2).mean()\n",
        "\n",
        "with torch.no_grad():\n",
        "  print('initiala felet är: {:.2f}'.format(loss(x, y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVwYdBulvbuT"
      },
      "source": [
        "Nu när vi har definierat en felfunktion kan vi optimera våra parametrar, så att\n",
        "dom minimerar felet. Vi kommer göra detta med Gradient Descent, alltså genom \n",
        "att uppdatera parametrarna med små steg i gradientens (motsatta) riktning. \n",
        "\n",
        "En av de viktigaste funktionaliteterna i maskininlärningsramverk är möjligheten\n",
        "att automatiskt beräkna gradienter. Torch kan alltså göra detta för oss. Det enda vi behöver göra är\n",
        "- Att specificera vilka parametrar vi vill räkna ut gradienter för.\n",
        "- Speca vilket värde vi vill räkna ut gradienten \"med avseende på\". \n",
        "\n",
        "Vi har redan tidigare specificerat att vi ska räkna ut gradienter för $a$ och $b$, så nedan tar vi iterativt fram felet för aktuella parametrar, beräknar gradienten, och uppdaterar dem. \n",
        "\n",
        "Detta visualiseras också, så man kan se hur parametrarna uppdateras över tid, och hur det så kallade \"loss-landskapet\" ser ut. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE79J3UH2leJ"
      },
      "source": [
        "\n",
        "# Här måste vi säga åt torch att inte beräkna gradienter, då vi ändrar på \n",
        "# parametrarnas innehåll.\n",
        "with torch.no_grad():\n",
        "  a.zero_()\n",
        "  b.zero_()\n",
        "\n",
        "\n",
        "# Spara parametrarnas värde (för visualisering)\n",
        "alist = [a.item()]\n",
        "blist = [b.item()]\n",
        "\n",
        "for _ in range(50):\n",
        "  for _ in range(10):\n",
        "    # Nollställ gradienter\n",
        "    if a.grad is not None:\n",
        "      a.grad.zero_()\n",
        "      b.grad.zero_()\n",
        "\n",
        "    # Beräkna felet för nuvarande parametrar\n",
        "    l = loss(x, y)\n",
        "\n",
        "    # Beräkna gradienten m.a.p. felet\n",
        "    l.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # För varje parameter, ta ett litet steg i gradientens motsatta riktning\n",
        "      a.add_(a.grad, alpha=-1e-2)\n",
        "      b.add_(b.grad, alpha=-1e-2)\n",
        "\n",
        "  # Spara var tionde parameter, så att vi kan visualiser dem senare\n",
        "  alist.append(a.item())\n",
        "  blist.append(b.item())\n",
        "\n",
        "# Nedan visualiserar vi felet, och vägen som parametrarna tar:\n",
        "aa, bb = torch.meshgrid(\n",
        "    torch.linspace(-4, 4, 102),\n",
        "    torch.linspace(-4, 4, 102))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ll = (aa + x.unsqueeze(1).unsqueeze(1) * bb - y.unsqueeze(1).unsqueeze(1)).pow(2).mean(0).log()\n",
        "ax.contourf(aa, bb, ll, )\n",
        "lines = ax.plot([],[], c='r')[0]\n",
        "ax.plot([true_a], [true_b], marker='x')\n",
        "ax.set_xlabel('a')\n",
        "ax.set_ylabel('b')\n",
        "\n",
        "def frame(i):\n",
        "  lines.set_data(alist[:i], blist[:i])\n",
        "  return lines, \n",
        "\n",
        "anim = animation.FuncAnimation(fig, frame, frames=len(alist), blit=True, repeat=True)\n",
        "anim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IG1z6Qrb-TD"
      },
      "source": [
        "Vi kan också visualisera vilka värden vår tränade modell ger: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsag-Q-y5up4"
      },
      "source": [
        "with torch.no_grad():\n",
        "  plt.plot(x, y)\n",
        "  plt.plot(x, y_pred(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SicghGFdBzbr"
      },
      "source": [
        "# MNIST, Maskininlärningens \"Hello World!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kZ1pIU2PN12"
      },
      "source": [
        "Vi börjar med att ladda ner datan, och tranfsormera den till pytorch-tensorer. \n",
        "\n",
        "Datan består av 60.000 träningsexempel och 10.000 testexempel med svartvita bilder och etiketter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3flAN7PCkpb"
      },
      "source": [
        "transform = torchvision.transforms.Compose(\n",
        "    [\n",
        "     torchvision.transforms.ToTensor(),\n",
        "     ]\n",
        ")\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(\n",
        "    '/files', \n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST(\n",
        "    '/files', \n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekHOOWIXQK5w"
      },
      "source": [
        "Datan är i form av *tensorer*: Alltså strukturerade flyttal. Nedan visualiserar vi hur det första träningsexemplet ser ut som en tensor (alltså en matris av 28 x 28 reella tal), i bildform, och vilken etikett bilden datapunkten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjgHHyfHxPxw"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "print('tensorform:')\n",
        "for row in mnist_train[0][0][0]:\n",
        "  print(' '.join(['{:.2f}'.format(val) for val in row]))\n",
        "\n",
        "print('bildform:')\n",
        "ax.imshow(mnist_train[0][0][0])\n",
        "ax.set_yticks([])\n",
        "ax.set_xticks([])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Etikett: {}'.format(mnist_train[0][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_gU7zYeJuC6"
      },
      "source": [
        "Vi pröver med en enkel modell:\n",
        "\n",
        "$y_d = b_d + \\sum_{ij} pixel_{ij} \\theta_{dij}$\n",
        "\n",
        "Denna modell associerar varje pixel i bilden med en poäng per siffra, och summerar sedan ihop alla pixlars poänger. \n",
        "\n",
        "Vi implementerar modellen som en pytorch-modul. Pytorch-moduler förenklar \n",
        "koden genom att modulen ansvarar för parametrarna, alltså \n",
        "$\\theta$ och $b$.\n",
        "\n",
        "När vi sedan tränar modellen uppdaterar vi $\\theta$ och $b$, med hjälp av derivatan mellan varje parameter och \"lossen\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdihK1j64NcP"
      },
      "source": [
        "class Simple(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # theta och nedan är modellens parametrar.\n",
        "    self.theta = torch.nn.Parameter(torch.randn(10, 28, 28).div_(28))\n",
        "    self.b = torch.nn.Parameter(torch.zeros(10))\n",
        "\n",
        "  def forward(self, image):\n",
        "    \"\"\"\n",
        "    Funktion som givet en bild ger en sannolikhetsdistribution över siffror.\n",
        "\n",
        "    Varje enskild pixel associeras med varje siffra, för att få fram sifferpoängen \n",
        "    för en bild, multipliceras pixelvärden med motsvarande pixel-siffervärden och\n",
        "    summeras sedan ihop.\n",
        "\n",
        "    alltså för en bild:\n",
        "\n",
        "    score[i] = b[i] = sum(image[h, w] * w[i, h, w] for h, w in [(0,0)..(28,28)])\n",
        "\n",
        "    image: en \"batch\" bilder med form (B x 1 x 28 x 28)\n",
        "    ger: en \"batch\" med sifferpoäng med form (B x 10)\n",
        "    \"\"\"\n",
        "\n",
        "    pixel_digit_score = image * self.theta\n",
        "    digit_score = self.b + pixel_digit_score.sum((2,3))\n",
        "    return digit_score\n",
        "\n",
        "  def loss(self, image, label):\n",
        "    self(image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0TBIwbeE7X7"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0IzM-RmZgnP"
      },
      "source": [
        "BATCH_SIZE=32\n",
        "EPOCHS = 2\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    mnist_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    mnist_test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "print('ANVÄNDER: \\n{}'.format(DEVICE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEO4E-t_ZoST"
      },
      "source": [
        "# Utvärdering\n",
        "\n",
        "Nedan definieras utvärderingsförfarandet.\n",
        "\n",
        "Funktionen tar en modell, går igenom all data i mnist-utvärderingsdatan, och returnerar den genomsnittliga lossen samt träffsäkerheten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MQZtgn2ZdiZ"
      },
      "source": [
        "@torch.no_grad()\n",
        "def eval_model(model):\n",
        "  N = len(mnist_test)\n",
        "\n",
        "  # Skapa en tqdm-progress bar\n",
        "  batches = tqdm.tqdm(test_dataloader)\n",
        "\n",
        "  # Initialiser statistik\n",
        "  hits = torch.zeros(()).to(DEVICE)\n",
        "  loss = torch.zeros(()).to(DEVICE)\n",
        "  for image, label in batches:\n",
        "    image = image.to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "\n",
        "    # Beräkna sifferpoängen enligt modellen\n",
        "    scores = model(image)\n",
        "\n",
        "    #Uppdatera loss och hits\n",
        "    loss += torch.nn.functional.cross_entropy(scores, label, reduction='sum')\n",
        "    hits += (scores.argmax(1) == label).sum()\n",
        "\n",
        "  # Normalisera loss och hits så att vi får genomsnittlig loss och accuracy\n",
        "  loss = (loss / N).item()\n",
        "  acc = (hits / N).item()\n",
        "\n",
        "\n",
        "  return loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snpgAR2lZsiu"
      },
      "source": [
        "# Träning\n",
        "\n",
        "Nedan definieras ett träningsförfarande för en epok. \n",
        "\n",
        "Funktionen tar en modell och en optimerare, och går igenom all data i mnist-träningsdatan, och uppdaterar modellen enligt optimeraren. \n",
        "\n",
        "Notera att loss-funktionen, alltså det vi vill minimera, kräver både indata\n",
        "i form av bilder, och \"utdata\" i form av sifferetiketter.\n",
        "\n",
        "Detta är alltså ett exempel på *övervakad inlärning* och *klassificering*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4seAJWEvBLo"
      },
      "source": [
        "\n",
        "def train_epoch(model, optimizer):\n",
        "  batches = tqdm.tqdm(train_dataloader)\n",
        "\n",
        "  for ix, (image, label) in enumerate(batches):\n",
        "    image = image.to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "\n",
        "    # Nollställ parametrarnas gradienter\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Beräkna sifferpoängen för bilderna.\n",
        "    scores = model(image)\n",
        "\n",
        "    # Givet Sifferpoängen och den riktiga siffran beräknas en loss.\n",
        "    loss = torch.nn.functional.cross_entropy(scores, label)\n",
        "    \n",
        "    # Beräkna gradienten av lossen med avseende på modellens parametrar.\n",
        "    loss.backward()\n",
        "\n",
        "    # Uppdatera parametrarna\n",
        "    optimizer.step()\n",
        "\n",
        "    if ix % 10 == 0:\n",
        "      batches.set_description('loss {:.2f}'.format(loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q3fm94cXW9d"
      },
      "source": [
        "# Träningsloop\n",
        "Nedan är en träningsloop. \n",
        "Vi börjar med att initialisera en ny modell, och flytta den till GPUn.\n",
        "\n",
        "Därefter skapar vi en optimerare, som ansvarar för att uppdatera modellens parametrar baserat på deras gradienter.\n",
        "\n",
        "Loopen går ut på att gå igenom all data EPOCH gånger, och per epok träna modellen på alla träningsdata (*train_epoch*), samt utvärdera den på utvärderingsdatan (*eval_model*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4j1RO5xyjTg"
      },
      "source": [
        "\n",
        "#Initialisera en ny modell (och lägg den på GPUn)\n",
        "model = Simple().to(device=DEVICE)\n",
        "\n",
        "# SGD står för Stochastic Gradient Descent och är den enklaste gradient-baserade\n",
        "# Optimeraren. Den tar helt enkelt ett steg i gradientens riktning viktat med\n",
        "# lr (learning rate).\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Utvärdera modellen\n",
        "  print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(epoch, *eval_model(model)))\n",
        "\n",
        "  # Träna modellen på all träningsdata\n",
        "  train_epoch(model, optimizer)\n",
        "\n",
        "#Utvärdera modellen\n",
        "print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(EPOCHS, *eval_model(model)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6SOsXgewTmZ"
      },
      "source": [
        "# En mer invecklad modell\n",
        "\n",
        "Nu när vi lyckats träna en enkel modell på MNIST kan vi gå vidare till att träna\n",
        "en mer komplicerad modell. Tack vare pytorch är detta relativt enkelt att göra:\n",
        "Vi behöver bara definiera en pytorch modul som beskriver någon funktion som mappar bild (i form av tensorer) till sifferpoänger.\n",
        "\n",
        "Eftersom pytorch hanterar gradientberäkningarna, och vi har definierat vår funktion som en pytorch-modul, kan vi enkelt stoppa in dess parametrar i en optimerare: Träningsloopen ser exakt likadan ut. \n",
        "\n",
        "Den mer invecklade modellen är inte en särskilt bra bildmodell, men ett typexempel av vad man kan göra. Skrivet som vektorer och matrismultiplikationer gör modellen följande:\n",
        " \n",
        "\n",
        "$\\mathbf{h}_{l+1} = \\max(\\mathbf{\\beta}_l + \\mathbf{h}_l \\mathbf{\\theta}_l, 0)  $\n",
        "\n",
        "$\\mathbf{y} = \\mathbf{\\beta}_L + \\mathbf{h}_L \\mathbf{\\theta}_L$\n",
        "\n",
        "där $\\mathbf{h}_0$ är bilden i tillplattad vektorform, och $\\mathbf{h}_{l+1}$ är en vektor med aktiveringar för lager $l+1$, och $L$ är antalet lager mellan indata och utdata. Antalet lager specificeras när man initialiserar modellen: Deep(12, 20) har två \"gömda\" lager, där det första har storlek 12, och de andra har storlek 20. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYMcbxm8ZZew"
      },
      "source": [
        "class Deep(torch.nn.Module):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  def __init__(self, *hidden_dims):\n",
        "    super().__init__()\n",
        "    sizes = [28*28, *hidden_dims]\n",
        "\n",
        "    inout = zip(sizes, sizes[1:])\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    indim = 28*28\n",
        "\n",
        "    for outdim in hidden_dims:\n",
        "      layers.append(torch.nn.Linear(indim, outdim, bias=True))\n",
        "      layers.append(torch.nn.ReLU())\n",
        "      indim = outdim\n",
        "    \n",
        "    layers.append(torch.nn.Linear(indim, 10, bias=True))\n",
        "    \n",
        "    self.f = torch.nn.Sequential(*layers)\n",
        "  \n",
        "  def forward(self, image):\n",
        "    (B, C, W, H) = image.shape\n",
        "    return self.f(image.reshape(B, W*H))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQr_X4U0lWre"
      },
      "source": [
        "#Initialisera en ny modell (och lägg den på GPUn)\n",
        "\n",
        "# Deep() är identisk med modellen \"Simple\", men man kan lägga till fler lager\n",
        "# i modellen genom att instantiera den med Deep(h1, h2, h3, ...). \n",
        "\n",
        "#model = Deep().to(device=DEVICE)\n",
        "#model = Deep(20).to(device=DEVICE)\n",
        "model = Deep(20, 40, 20, 12).to(device=DEVICE)\n",
        "\n",
        "print(model)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Adam är en mer invecklad optimerare, som oftast leder till bra resultat.\n",
        "#optimizer = torch.optim.AdamW(model.parameters())\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Utvärdera modellen\n",
        "  print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(epoch, *eval_model(model)))\n",
        "\n",
        "  # Träna modellen på all träningsdata\n",
        "  train_epoch(model, optimizer)\n",
        "\n",
        "#Utvärdera modellen\n",
        "print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(EPOCHS, *eval_model(model)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yikDs2aA3a7b"
      },
      "source": [
        "# Förtränad modell\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CAlVqM81Kh3"
      },
      "source": [
        "I https://pytorch.org/docs/stable/nn.html# finns fler exempel på lager i neurala nätverk (likt torch.nn.Linear, eller torch.nn.ReLU). Det går också bra att göra beräkningar direkt, som i modellen Simple. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLZp-vPELQlb"
      },
      "source": [
        "D = 10\n",
        "(28*28+D)*D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETeTOmfHlRjX"
      },
      "source": [
        "\n",
        "\n",
        "prod((1,2,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aArQMcanl0vm"
      },
      "source": [
        "\n",
        "\n",
        "torch.randn(2,3,4).dim()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQbWRb9pneDd"
      },
      "source": [
        "\n",
        "\n",
        "s = torch.randn(2,3,4,).shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "s[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7z1XN5M7B0B"
      },
      "source": [
        "class Residualize(torch.nn.Module):\n",
        "  def __init__(self, module):\n",
        "    self.f = module\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return x + self.f(x)\n",
        "\n",
        "class Linearish(torch.nn.Module):\n",
        "  def __init__(self, inshape, outshape, bias=True):\n",
        "    insize = 1\n",
        "    for s in inshape:\n",
        "      insize *= s\n",
        "  \n",
        "    outsize = 1\n",
        "    for s in outshape:\n",
        "      outshape *= s\n",
        "\n",
        "    self.f = torch.nn.Linear(insize, outsize, bias=bias)\n",
        "\n",
        "    self.insize = insize\n",
        "    self.outsize = outsize\n",
        "    self.indim = len(inshape)\n",
        "    self.inshape = inshape\n",
        "    self.outshape = outshape\n",
        "\n",
        "  def forward(self, x):\n",
        "    inshape = x.shape[:-self.indim] + (self.insize,)\n",
        "    outshape = x.shape[:-self.indim] + self.outshape\n",
        "    \n",
        "    return self.f(x.reshape(inshape)).reshape(outshape)\n",
        "\n",
        "\n",
        "class DeepRes(torch.nn.Module):\n",
        "  def __init__(self, dim, depth):\n",
        "    super().__init__()\n",
        "    layers = []\n",
        "\n",
        "    self.imagemap = torch.nn.Sequential(\n",
        "        torch.nn.Linear(28*28, (depth + 1) * dim),\n",
        "        torch.nn.ReLU(),\n",
        "        lambda x: x.reshape(-1, self.depth+1, self.dim),\n",
        "        torch.nn.LayerNorm((dim)))\n",
        "\n",
        "    for _ in range(depth):\n",
        "      layers.append(torch.nn.Sequential(\n",
        "          torch.nn.Linear(dim, dim),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.LayerNorm((dim,))\n",
        "        ))\n",
        "      \n",
        "    self.depth = depth\n",
        "    self.dim = dim\n",
        "    self.layers = torch.nn.ModuleList(layers)\n",
        "    self.final = torch.nn.Linear(dim, 10)\n",
        "\n",
        "  def forward(self, image):\n",
        "    B, C, H, W = image.shape\n",
        "    flat = image.reshape(B, H*W)\n",
        "    states = self.imagemap(flat).reshape(B, self.depth+1, self.dim)\n",
        "    acc = states[:, 0]\n",
        "\n",
        "    for i in range(self.depth):\n",
        "      acc = self.layers[i](acc + states[:, i+1]) + acc\n",
        "\n",
        "    return self.final(acc)\n",
        "\n",
        "\n",
        "#model = Deep(20).to(device=DEVICE)\n",
        "model = DeepRes(30, 20).to(device=DEVICE)\n",
        "\n",
        "#print(model)\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Adam är en mer invecklad optimerare, som oftast leder till bra resultat.\n",
        "# optimizer = torch.optim.AdamW(model.parameters())\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Utvärdera modellen\n",
        "  print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(epoch, *eval_model(model)))\n",
        "\n",
        "  # Träna modellen på all träningsdata\n",
        "  train_epoch(model, optimizer)\n",
        "\n",
        "#Utvärdera modellen\n",
        "print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(EPOCHS, *eval_model(model)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq7kq-RB5qmG"
      },
      "source": [
        "class Pretrained(torch.nn.Module):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  def __init__(self, *hidden_dims):\n",
        "    super().__init__()\n",
        "    self.t = torchvision.transforms.Resize((256,))\n",
        "\n",
        "    self.f = torchvision.models.resnet18(pretrained=True, progress=True)\n",
        "\n",
        "  \n",
        "  def forward(self, image):\n",
        "    (B, C, W, H) = image.shape\n",
        "    return self.f(self.t(image).expand(-1, 3, -1, -1))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqCt1NXy7rQ-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G82nSuEp7uZ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}