{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop Primer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekgren/workshop/blob/main/Day1/Workshop_Primer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7Zmsd_GNJYa"
      },
      "source": [
        "# MNIST, Maskininlärningens \"Hello World!\"\n",
        "\n",
        "I första lab-delen av workshoppen ska vi gå igenom ett exempel med bildigenkänning: MNIST.\n",
        "\n",
        "MNIST är ett dataset bestående av små bilder (28 x 28 pixlar) av siffror (0-9), med tillhörande sifferetikett (alltså siffran bilden föreställer). \n",
        "\n",
        "Datan består av 60.000 träningsexempel och 10.000 testexempel.\n",
        "\n",
        "Vi börjar med att importera pythonpaket som kommer användas.\n",
        "\n",
        "torch och torchvision är maskininlärningsbibliotek. \n",
        "\n",
        "*torch* är grundpaketet. Detta innehåller matematiska funnktioner, GPU-funktionalitet, ramverk för att definiera modeller, optimiera dessa m.m. och i synnerhet autograd: Ramverket som används för att beräkna gradienter.\n",
        "\n",
        "*torchvision* är ett tillägg till torch för just bildhantering.\n",
        "\n",
        "*matplotlib* är ett bibliotek för att visa diagram och bilder.\n",
        "\n",
        "*tqdm* är ett bibliotek som visar \"progress bars\".\n",
        "\n",
        "itertools är ett internt pythonbibliotek med hjälpfunktioner för iteratorer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUgEPhGYxkj8"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import itertools"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kZ1pIU2PN12"
      },
      "source": [
        "Vi börjar med att ladda ner datan, och tranfsormera den till pytorch-tensorer. \n",
        "Datan består av 60.000 träningsexempel och 10.000 testexempel med svartvita bilder och etiketter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3flAN7PCkpb"
      },
      "source": [
        "transform = torchvision.transforms.Compose(\n",
        "    [\n",
        "     torchvision.transforms.ToTensor(),\n",
        "     ]\n",
        ")\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(\n",
        "    '/files', \n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST(\n",
        "    '/files', \n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekHOOWIXQK5w"
      },
      "source": [
        "Datan är i form av *tensorer*: Alltså strukturerade flyttal. Nedan visualiserar vi hur det första träningsexemplet ser ut som en tensor (alltså en matris av 28 x 28 reella tal), i bildform, och vilken etikett bilden datapunkten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjgHHyfHxPxw"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "print('tensorform:')\n",
        "for row in mnist_train[0][0][0]:\n",
        "  print(' '.join(['{:.2f}'.format(val) for val in row]))\n",
        "\n",
        "print('bildform:')\n",
        "ax.imshow(mnist_train[0][0][0])\n",
        "ax.set_yticks([])\n",
        "ax.set_xticks([])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Etikett: {}'.format(mnist_train[0][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_gU7zYeJuC6"
      },
      "source": [
        "Vi pröver med en enkel modell:\n",
        "\n",
        "$y_d = b_d + \\sum_{ij} pixel_{ij} \\theta_{dij}$\n",
        "\n",
        "Denna modell associerar varje pixel i bilden med en poäng per siffra, och summerar sedan ihop alla pixlars poänger. \n",
        "\n",
        "Vi implementerar modellen som en pytorch-modul. Pytorch-moduler förenklar \n",
        "koden genom att modulen ansvarar för parametrarna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdihK1j64NcP"
      },
      "source": [
        "class Simple(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.theta = torch.nn.Parameter(torch.randn(10, 28, 28).div_(28))\n",
        "    self.b = torch.nn.Parameter(torch.zeros(10))\n",
        "\n",
        "  def forward(self, image):\n",
        "    \"\"\"\n",
        "    Funktion som givet en bild ger en sannolikhetsdistribution över siffror.\n",
        "\n",
        "    Varje enskild pixel associeras med varje siffra, för att få fram sifferpoängen \n",
        "    för en bild, multipliceras pixelvärden med motsvarande pixel-siffervärden och\n",
        "    summeras sedan ihop.\n",
        "\n",
        "    alltså för en bild:\n",
        "\n",
        "    score[i] = b[i] = sum(image[h, w] * w[i, h, w] for h, w in [(0,0)..(28,28)])\n",
        "\n",
        "    image: en \"batch\" bilder med form (B x 1 x 28 x 28)\n",
        "    ger: en \"batch\" med sifferpoäng med form (B x 10)\n",
        "    \"\"\"\n",
        "\n",
        "    pixel_digit_score = image * self.theta\n",
        "    digit_score = self.b + pixel_digit_score.sum((2,3))\n",
        "    return digit_score\n",
        "\n",
        "  def loss(self, image, label):\n",
        "    self(image)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0IzM-RmZgnP"
      },
      "source": [
        "BATCH_SIZE=32\n",
        "EPOCHS = 2\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    mnist_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    mnist_test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEO4E-t_ZoST"
      },
      "source": [
        "# Utvärdering\n",
        "\n",
        "Nedan definieras utvärderingsförfarandet.\n",
        "\n",
        "Funktionen tar en modell, går igenom all data i mnist-utvärderingsdatan, och returnerar den genomsnittliga lossen samt träffsäkerheten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MQZtgn2ZdiZ"
      },
      "source": [
        "@torch.no_grad()\n",
        "def eval_model(model):\n",
        "  N = len(mnist_test)\n",
        "\n",
        "  # Skapa en tqdm-progress bar\n",
        "  batches = tqdm.tqdm(test_dataloader)\n",
        "\n",
        "  # Initialiser statistik\n",
        "  hits = torch.zeros(()).to(DEVICE)\n",
        "  loss = torch.zeros(()).to(DEVICE)\n",
        "  for image, label in batches:\n",
        "    image = image.to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "\n",
        "    # Beräkna sifferpoängen enligt modellen\n",
        "    scores = model(image)\n",
        "\n",
        "    #Uppdatera loss och hits\n",
        "    loss += torch.nn.functional.cross_entropy(scores, label, reduction='sum')\n",
        "    hits += (scores.argmax(1) == label).sum()\n",
        "\n",
        "  # Normalisera loss och hits så att vi får genomsnittlig loss och accuracy\n",
        "  loss = (loss / N).item()\n",
        "  acc = (hits / N).item()\n",
        "\n",
        "\n",
        "  return loss, acc"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snpgAR2lZsiu"
      },
      "source": [
        "# Träning\n",
        "\n",
        "Nedan definieras ett träningsförfarande för en epok. \n",
        "\n",
        "Funktionen tar en modell och en optimerare, och går igenom all data i mnist-träningsdatan, och uppdaterar modellen enligt optimeraren. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4seAJWEvBLo"
      },
      "source": [
        "\n",
        "def train_epoch(model, optimizer):\n",
        "  batches = tqdm.tqdm(train_dataloader)\n",
        "\n",
        "  for ix, (image, label) in enumerate(batches):\n",
        "    image = image.to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "\n",
        "    # Nollställ parametrarnas gradienter\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Beräkna sifferpoängen för bilderna.\n",
        "    scores = model(image)\n",
        "\n",
        "    # Givet Sifferpoängen och den riktiga siffran beräknas en loss.\n",
        "    loss = torch.nn.functional.cross_entropy(scores, label)\n",
        "    \n",
        "    # Beräkna gradienten av lossen med avseende på modellens parametrar.\n",
        "    loss.backward()\n",
        "\n",
        "    # Uppdatera parametrarna\n",
        "    optimizer.step()\n",
        "\n",
        "    if ix % 10 == 0:\n",
        "      batches.set_description('loss {:.2f}'.format(loss.item()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q3fm94cXW9d"
      },
      "source": [
        "# Träningsloop\n",
        "Nedan är en träningsloop. \n",
        "Vi börjar med att initialisera en ny modell, och flytta den till GPUn.\n",
        "\n",
        "Därefter skapar vi en optimerare, som ansvarar för att uppdatera modellens parametrar baserat på deras gradienter.\n",
        "\n",
        "Loopen går ut på att gå igenom all data EPOCH gånger, och per epok träna modellen på alla träningsdata (*train_epoch*), samt utvärdera den på utvärderingsdatan (*eval_model*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4j1RO5xyjTg"
      },
      "source": [
        "\n",
        "#Initialisera en ny modell (och lägg den på GPUn)\n",
        "model = Simple().to(device=DEVICE)\n",
        "\n",
        "# SGD står för Stochastic Gradient Descent och är den enklaste gradient-baserade\n",
        "# Optimeraren. Den tar helt enkelt ett steg i gradientens riktning viktat med\n",
        "# lr (learning rate).\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Utvärdera modellen\n",
        "  print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(epoch, *eval_model(model)))\n",
        "\n",
        "  # Träna modellen på all träningsdata\n",
        "  train_epoch(model, optimizer)\n",
        "\n",
        "#Utvärdera modellen\n",
        "print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(EPOCHS, *eval_model(model)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6SOsXgewTmZ"
      },
      "source": [
        "# En mer invecklad modell\n",
        "\n",
        "Nu när vi lyckats träna en enkel modell på MNIST kan vi gå vidare till att träna\n",
        "en mer komplicerad modell. Tack vare pytorch är detta relativt enkelt att göra:\n",
        "Vi behöver bara definiera en pytorch modul som beskriver någon funktion som mappar bild (i form av tensorer) till sifferpoänger.\n",
        "\n",
        "Eftersom pytorch hanterar gradientberäkningarna, och vi har definierat vår funktion som en pytorch-modul, kan vi enkelt stoppa in dess parametrar i en optimerare: Träningsloopen ser exakt likadan ut. \n",
        "\n",
        "Den mer invecklade modellen är inte en särskilt bra bildmodell, men ett typexempel av vad man kan göra. Skrivet som vektorer och matrismultiplikationer gör modellen följande:\n",
        " \n",
        "\n",
        "$\\mathbf{h}_{l+1} = \\max(\\mathbf{\\beta}_l + \\mathbf{h}_l \\mathbf{\\theta}_l, 0)  $\n",
        "\n",
        "$\\mathbf{y} = \\mathbf{\\beta}_L + \\mathbf{h}_L \\mathbf{\\theta}_L$\n",
        "\n",
        "där $\\mathbf{h}_0$ är bilden i tillplattad vektorform, och $\\mathbf{h}_l+1$ är en vektor med aktiveringar för lager $l+1$. Antalet aktiveringar specificeras när man initialiserar modellen: Deep(12, 20) har två \"gömda\" lager, där det första har storlek 12, och de andra har storlek 20. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYMcbxm8ZZew"
      },
      "source": [
        "class Deep(torch.nn.Module):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  def __init__(self, *hidden_dims):\n",
        "    super().__init__()\n",
        "    sizes = [28*28, *hidden_dims]\n",
        "\n",
        "    inout = zip(sizes, sizes[1:])\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    indim = 28*28\n",
        "\n",
        "    for outdim in hidden_dims:\n",
        "      layers.append(torch.nn.Linear(indim, outdim, bias=True))\n",
        "      layers.append(torch.nn.ReLU())\n",
        "      indim = outdim\n",
        "    \n",
        "    layers.append(torch.nn.Linear(indim, 10, bias=True))\n",
        "    \n",
        "    self.f = torch.nn.Sequential(*layers)\n",
        "  \n",
        "  def forward(self, image):\n",
        "    (B, C, W, H) = image.shape\n",
        "    return self.f(image.reshape(B, W*H))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQr_X4U0lWre"
      },
      "source": [
        "#Initialisera en ny modell (och lägg den på GPUn)\n",
        "\n",
        "# Deep() är identisk med modellen \"Simple\", men man kan lägga till fler lager\n",
        "# i modellen genom att instantiera den med Deep(h1, h2, h3, ...). \n",
        "\n",
        "#model = Deep().to(device=DEVICE)\n",
        "#model = Deep(20).to(device=DEVICE)\n",
        "model = Deep(20, 40, 20, 12).to(device=DEVICE)\n",
        "\n",
        "print(model)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Adam är en mer invecklad optimerare, som oftast leder till bra resultat.\n",
        "#optimizer = torch.optim.AdamW(model.parameters())\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Utvärdera modellen\n",
        "  print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(epoch, *eval_model(model)))\n",
        "\n",
        "  # Träna modellen på all träningsdata\n",
        "  train_epoch(model, optimizer)\n",
        "\n",
        "#Utvärdera modellen\n",
        "print('\\nafter {} epochs, loss {:.2f}, accuracy: {:.1%}'.format(EPOCHS, *eval_model(model)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CAlVqM81Kh3"
      },
      "source": [
        "I https://pytorch.org/docs/stable/nn.html# finns fler exempel på lager i neurala nätverk (likt torch.nn.Linear, eller torch.nn.ReLU). Det går också bra att göra beräkningar direkt, som i modellen Simple. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zef2O-x5lcwO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}