{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop squad sv.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekgren/workshop/blob/main/Day2/QA_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLDgGd-cvIJM"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rVaJCvku_ET"
      },
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import torch\n",
        "import copy\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu7XAwjgvCQP"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
        "kb_bert = transformers.AutoModel.from_pretrained('KB/bert-base-swedish-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwWKM13Bv8Qh"
      },
      "source": [
        "dataset = datasets.load_dataset('stsb_mt_sv')\n",
        "train_ds = dataset['train']\n",
        "test_ds = dataset['test']\n",
        "eval_ds = dataset['validation']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY7bY27Wz81V"
      },
      "source": [
        "def encode(*texts):\n",
        "  assert 1 <= len(texts) <= 2\n",
        "  return tokenizer(*texts, padding=True, truncation=True, max_length=512, return_tensors='pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K-oXDTY4Uw2"
      },
      "source": [
        "train_ds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJaV1n6_zN-d"
      },
      "source": [
        "def collate_paired(rows):\n",
        "  s1s = [row['sentence1'] for row in rows]\n",
        "  s2s = [row['sentence2'] for row in rows]\n",
        "  scores = torch.tensor([row['score'] for row in rows])\n",
        "  return encode(s1s, s2s), scores\n",
        "\n",
        "def collate_dual(rows):\n",
        "  s1s = [row['sentence1'] for row in rows]\n",
        "  s2s = [row['sentence2'] for row in rows]\n",
        "  scores = torch.tensor([row['score'] for row in rows])\n",
        "  return encode(s1s), encode(s2s), scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjH8Eq1_1hE2"
      },
      "source": [
        "COLLATER = collate_paired\n",
        "train_dl = torch.utils.data.DataLoader(  \n",
        "    train_ds,\n",
        "    collate_fn=COLLATER,\n",
        "    shuffle=True,\n",
        "    batch_size=8,\n",
        "    pin_memory=True,\n",
        "  )\n",
        "test_dl = torch.utils.data.DataLoader(  \n",
        "    test_ds,\n",
        "    collate_fn=COLLATER,\n",
        "    shuffle=False,\n",
        "    batch_size=8,\n",
        "    pin_memory=True,\n",
        "  )\n",
        "eval_dl = torch.utils.data.DataLoader(  \n",
        "    eval_ds,\n",
        "    collate_fn=COLLATER,\n",
        "    shuffle=False,\n",
        "    batch_size=8,\n",
        "    pin_memory=True,\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSmDeCgx1von"
      },
      "source": [
        "\n",
        "class PairedModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = copy.deepcopy(kb_bert)\n",
        "    self.linear = torch.nn.Linear(768, 1)\n",
        "  \n",
        "  def forward(self, data):\n",
        "    return self.linear(self.model(**data)['pooler_output']).squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YfF9H7D8HPj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eViPm_oo8JM5"
      },
      "source": [
        "\n",
        "batch, score = next(iter(train_dl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH0s4FAkAZzC"
      },
      "source": [
        "\n",
        "paired_model(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmDAs9tD4mA-"
      },
      "source": [
        "paired_model = PairedModel().cuda()\n",
        "optimizer = torch.optim.AdamW(paired_model.parameters())\n",
        "EPOCHS = 1\n",
        "for epoch in range(EPOCHS):\n",
        "  batches = tqdm.tqdm(train_dl)\n",
        "  for batch, score in batches:\n",
        "    batch = {k : v.cuda() for k, v in batch.items()}\n",
        "    score = score.cuda()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    prediction = paired_model(batch)\n",
        "    \n",
        "    loss = torch.nn.functional.mse_loss(prediction, score)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    batches.set_description('{:.2f}'.format(loss.item()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypbans-GBEk0"
      },
      "source": [
        "# Namnigenkänning (Named Entity Recognition)\n",
        "\n",
        "Exempel: Namnigenkänning\n",
        "\n",
        "Kort förklaring av namnigenkänning\n",
        "\n",
        "BERT base fine-tuned for Swedish NER. This model is fine-tuned on the SUC 3.0 dataset.\n",
        "\n",
        "Entity types used are TME for time, PRS for personal names, LOC for locations, EVN for events and ORG for organisations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPQM0yyp7SSM"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIJqRr6FBFVQ"
      },
      "source": [
        "nlp('Hej jag heter Arne och jag vill byta lösenord.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO2N4FMQBMba"
      },
      "source": [
        "# Exempel KB-Bert ordmaskning\n",
        "\n",
        "Maskar ord med Bert\n",
        "\n",
        "https://github.com/af-ai-center/SweBERT/blob/master/getting_started_with_swebert.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56OvHSUtBPqg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}