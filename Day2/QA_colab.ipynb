{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Workshop squad sv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekgren/workshop/blob/main/Day2/QA_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiuQBzImbVs4"
      },
      "source": [
        "# NLU, Transformers, Bert m.m.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLDgGd-cvIJM"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rVaJCvku_ET"
      },
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import torch\n",
        "import copy\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0B_7TjI7fVq"
      },
      "source": [
        "# Exempel KB-Bert med ordmaskning\n",
        "\n",
        "När man förtränar Bert modeller så lär de sig språklig statistik genom att se massa text, maska ord och gissa vilket ord som bör vara på en den maskerade platsen. I slutändan är det nästan aldrig gissa ord som modellerna används till utan man anpassar (finetunear) dem till en annan uppgift. Men för att illustrera hur den förtränade modellen fungerar så gör vi en maskningsuppgift.\n",
        "\n",
        "Vi börjar med att ladda KB-Bert och dess tokeniserare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_0WDNy92X2F"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
        "model = transformers.BertForMaskedLM.from_pretrained('KB/bert-base-swedish-cased')\n",
        "print(type(model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou9eCXS93EuW"
      },
      "source": [
        "Vi hittar på en exempelmening."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_A_Ntyl2tV-"
      },
      "source": [
        "example = 'Hej och välkommen till Trafikverket! Myndigheten för dig som gillar vägar, bilar och tåg.'\n",
        "example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgMb_cAm5zkt"
      },
      "source": [
        "Bert är tränad med speciella ord i början och slutet av meningar, [CLS] och [SEP]. Modellen förutsätter att de är med när du stoppar in en mening. Om du skapar en batch med en huggingface tokeniserare görs detta automatiskt av tokeniseraren men i det här exemplet lägger vi till dem manuellt till exempelmeningen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YcMruOq8mUi"
      },
      "source": [
        "example_preprocessed = f'[CLS] {example} [SEP]'\n",
        "example_preprocessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra0PEXAHQ5bJ"
      },
      "source": [
        "Nu har vi vår mening i textform och nästa steg är att dela upp den i tokens med vår tokeniserare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMWJ1z2bxxIB"
      },
      "source": [
        "tokens = tokenizer.tokenize(example_preprocessed)\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEWij8oQRFuW"
      },
      "source": [
        "Sedan gör vi om våra tokens till index som modellen använder för att ta fram en sifferrepresentation av de tokens som går in i modellen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWpLDmHByA0L"
      },
      "source": [
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(indexed_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHTh_7PvRGIp"
      },
      "source": [
        "Nu till själva uppgiften som vi skall utföra med modellen. Vi väljer ut ett ord som ligger på plats 5 med nollindexering, \"Trafikverket\", och ersätter det med en [MASK] token. Detta för att sedan låta modellen givet resten av meningen gissa vilket ord som passar bäst in istället för [MASK]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF20g_vpyTa3"
      },
      "source": [
        "masked_index = 5\n",
        "tokens[masked_index] = '[MASK]'\n",
        "print(tokens)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"\\nToken index:\", indexed_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHCoN2fRRH5P"
      },
      "source": [
        "Sedan matar vi in vår exempelmening i KB-Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkiev0nNzT0I"
      },
      "source": [
        "# Transformers använder dropout under träning. Om man vill säga åt modellen\n",
        "# att stänga av dropout använder man model.eval(). Detta bör man göra när man\n",
        "# applicerar model, som här.\n",
        "\n",
        "_ = model.eval()\n",
        "\n",
        "# För att spara på datorkraft säger åt torch att inte räkna fram gradienter.\n",
        "with torch.no_grad():\n",
        "    outputs = model(torch.tensor([indexed_tokens]))\n",
        "\n",
        "predictions = outputs[0]\n",
        "print(predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Y9Q9MSzhQZ"
      },
      "source": [
        "predicted_index = torch.topk(predictions[0, masked_index], k=5)\n",
        "print(predicted_index.indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmOPOCzxzzXD"
      },
      "source": [
        "predicted_token = tokenizer.convert_ids_to_tokens(predicted_index.indices)\n",
        "print(predicted_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ZkRsqMZRxS"
      },
      "source": [
        "# Ladda modeller och tokeniserare\n",
        "\n",
        "Vi börjar med att ladda ner modell och tokeniserare från huggingface.\n",
        "\n",
        "Både modell och tokeniserare är tränad på Kungliga Bibliotekets data, och har använts i många svenska NLP-applikationer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eXP9702V640"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
        "model = transformers.AutoModel.from_pretrained('KB/bert-base-swedish-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9EeGPz2PE5d"
      },
      "source": [
        "# Finetuning: Semantisk likhet mellan *meningar*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu7XAwjgvCQP"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
        "kb_bert = transformers.AutoModel.from_pretrained('KB/bert-base-swedish-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDudvs-vYbX7"
      },
      "source": [
        "## Data\n",
        "\n",
        "För detta exempel använder vi STS-B-datasetet maskinöversatt till svenska. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziDHJ_-mV644"
      },
      "source": [
        "dataset = datasets.load_dataset('stsb_mt_sv')\n",
        "train_ds = dataset['train']\n",
        "test_ds = dataset['test']\n",
        "eval_ds = dataset['validation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD4GhwIu2ev6"
      },
      "source": [
        "Det är alltid bra att inspektera datan så vi tittar på några exempel från datasetet för att bilda oss en uppfattning om uppgiften."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6QOumAH1xZl"
      },
      "source": [
        "for ix in range(10):\n",
        "    print(dataset['train'][ix])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87mZGUp12522"
      },
      "source": [
        "I utskriften ovanför ser vi att datan är i json format eller snarare en python dictionary. Vi skriver lite kod för att formatera den så att den är mer lättläst.  \n",
        "\n",
        "Datan består av tre delar: 'sentence1', 'sentence2' samt 'score'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bPoCcU-V646"
      },
      "source": [
        "for ix in range(10):\n",
        "  s1 = train_ds[ix]['sentence1']\n",
        "  s2 = train_ds[ix]['sentence2']\n",
        "  score = train_ds[ix]['score']\n",
        "  print('{:.2f}: {:^40} | {:^40}'.format(score, s1, s2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oCiCZuLYreh"
      },
      "source": [
        "## Dataloaders\n",
        "\n",
        "För att kunna mata nätverket med data så behöver vi göra dataloaders. Dataloaders samlar ihop datan till rätt format samt batchar den.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F-6H6zMV646"
      },
      "source": [
        "def encode(*texts):\n",
        "    # Den här funktionen tar in en lista med texter\n",
        "    # och returnerar tokeniserad data i pytorch format.\n",
        "    assert 1 <= len(texts) <= 2\n",
        "    return tokenizer(*texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "def collate_paired(rows):\n",
        "    # Den här funktionen parar ihop två meningar med en [SEP] token mellan dem.\n",
        "    # Detta för att kunna fineatunea på STS.\n",
        "    s1s = [row['sentence1'] for row in rows]\n",
        "    s2s = [row['sentence2'] for row in rows]\n",
        "    scores = torch.tensor([row['score'] for row in rows])\n",
        "    return encode(s1s, s2s), scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3SXP52F51ib"
      },
      "source": [
        "Nedan förbereder vi \"dataloaders\" som är torchabstraktioner för att hantera data. Dessa hjälper till med att ladda datan parallelt (med multiprocessing),\n",
        "blanda datan, samt stycka upp den i mindre \"batches\": Detta har visat sig ge både bättre resultat när man tränar modeller, och är nödvändigt om man har stora modeller och många träningsdatapunkter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obRwA6AzxPa7"
      },
      "source": [
        "def make_dataloaders(collater, train_batch_size=8, test_batch_size=None):\n",
        "\n",
        "    if test_batch_size is None:\n",
        "        test_batch_size = 2 * train_batch_size\n",
        "\n",
        "    train_dl = torch.utils.data.DataLoader(  \n",
        "        train_ds,\n",
        "        collate_fn=collater,\n",
        "        shuffle=True,\n",
        "        batch_size=train_batch_size,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    test_dl = torch.utils.data.DataLoader(  \n",
        "        test_ds,\n",
        "        collate_fn=collater,\n",
        "        shuffle=False,\n",
        "        batch_size=test_batch_size,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    eval_dl = torch.utils.data.DataLoader(  \n",
        "        eval_ds,\n",
        "        collate_fn=collater,\n",
        "        shuffle=False,\n",
        "        batch_size=test_batch_size,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    return train_dl, test_dl, eval_dl\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL9VZzOZbCet"
      },
      "source": [
        "## En enkel sts-modell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7W13wUHV64-"
      },
      "source": [
        "class PairedModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = copy.deepcopy(kb_bert)\n",
        "        self.linear = torch.nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        return self.linear(self.model(**data)['pooler_output']).squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT7kqR4EY7M_"
      },
      "source": [
        "## Hjälpfunktioner\n",
        "\n",
        "Här definierar vi hjälpfunktioner för att räkna ut medelvärden, och för att \n",
        "flytta data till GPUer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWIUh60UY5lJ"
      },
      "source": [
        "\n",
        "class ExpMean(object):\n",
        "    \"\"\"\n",
        "    Class for calculating an online exponential mean\n",
        "    \"\"\"\n",
        "    def __init__(self, mean=None, alpha=0.1):\n",
        "        self.mean = None\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __iadd__(self, other):\n",
        "        if self.mean is None:\n",
        "            self.mean = other\n",
        "        else:\n",
        "            self.mean += (other - self.mean) * self.alpha\n",
        "        return self\n",
        "\n",
        "class WelfordMean(object):                                                    \n",
        "    \"\"\"                                                                       \n",
        "    Class for calculating an online weighted mean                             \n",
        "    \"\"\"                                                                       \n",
        "    def __init__(self, mean=0.0, weight=0.0):                                 \n",
        "        self.mean = mean                                                      \n",
        "        self.weight = weight                                                  \n",
        "                                                                            \n",
        "    def __iadd__(self, other):                                                \n",
        "    if type(other) is WelfordMean:                                        \n",
        "        self.weight += other.weight                                       \n",
        "        self.mean += (other.mean - self.mean) * other.weight / self.weight\n",
        "    else:                                                                 \n",
        "        self.weight += 1                                                  \n",
        "        self.mean += (other - self.mean) / self.weight                    \n",
        "    return self\n",
        "\n",
        "def to_cuda(xs):\n",
        "    if type(xs) is list:\n",
        "        return [to_cuda(x) for x in xs]\n",
        "    elif type(xs) is dict:\n",
        "        return {k: to_cuda(v) for k, v in xs.items()}\n",
        "    elif type(xs) is torch.Tensor:\n",
        "        return xs.cuda()\n",
        "    else:\n",
        "        raise ValueError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1xZEAjkX4cf"
      },
      "source": [
        "### Evaluering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S3KSjlTaW_l"
      },
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def eval_model(model, dataloader):\n",
        "    # Skapa en tqdm-progress bar\n",
        "    batches = tqdm.tqdm(dataloader)\n",
        "\n",
        "    # Initialisera statistik\n",
        "    acc_loss = WelfordMean()\n",
        "    for batch, score in batches:\n",
        "        # Stoppa datan på rätt \"plats\" (gpu)\n",
        "        batch = to_cuda(batch)\n",
        "        score = to_cuda(score)\n",
        "\n",
        "        # Beräkna sifferpoängen enligt modellen\n",
        "        prediction = model(batch)\n",
        "        loss = torch.nn.functional.mse_loss(prediction, score)\n",
        "        acc_loss += WelfordMean(loss.item(), len(batch))\n",
        "\n",
        "    return acc_loss.mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzvYrY5IX9Hz"
      },
      "source": [
        "### Träning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7As4m7zab167"
      },
      "source": [
        "def train_epoch(model, optimizer, dataloader):\n",
        "    # Skapa en tqdm-progress bar\n",
        "    batches = tqdm.tqdm(dataloader)\n",
        "\n",
        "    # Initialisera statistik\n",
        "    acc_loss = ExpMean()\n",
        "    for ix, (batch, score) in enumerate(batches):\n",
        "        # Stoppa datan på rätt \"plats\" (gpu)\n",
        "        batch = to_cuda(batch)\n",
        "        score = to_cuda(score)\n",
        "\n",
        "        # Nollställ parametrarnas gradienter\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Beräkna sifferpoängen enligt modellen\n",
        "        prediction = model(batch)\n",
        "\n",
        "        # Beräkna lossen (MSE)\n",
        "        loss = torch.nn.functional.mse_loss(prediction, score)\n",
        "\n",
        "        # Beräkna gradienten av lossen med avseende på modellens parametrar.\n",
        "        loss.backward()\n",
        "\n",
        "        # Uppdatera parametrarna\n",
        "        optimizer.step()\n",
        "\n",
        "        acc_loss += loss.item()\n",
        "\n",
        "        batches.set_description('loss {:.2f}'.format(acc_loss.mean))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e9a7JhKZhfb"
      },
      "source": [
        "## Träningsloopen\n",
        "\n",
        "Här tränar vi modellen! \n",
        "\n",
        "notera "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWrZ-5szV64_"
      },
      "source": [
        "model = PairedModel().cuda()\n",
        "train_dl, test_dl, eval_dl = make_dataloaders(collate_dual)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "EPOCHS = 1\n",
        "for epoch in range(EPOCHS):\n",
        "    # Utvärdera modellen\n",
        "    print('\\nafter {} epochs, loss {:.2f}'.format(epoch, eval_model(model, test_dl)))\n",
        "\n",
        "    # Träna modellen på all träningsdata\n",
        "    train_epoch(model, optimizer, train_dl)\n",
        "\n",
        "#Utvärdera modellen\n",
        "print('\\nafter {} epochs, loss {:.2f}'.format(EPOCHS, eval_model(model, test_dl)))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWA8ilpHWAeC"
      },
      "source": [
        "batch, score = next(iter(train_dl))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for predicted_score, text, true_score in zip(\n",
        "        model(to_cuda(batch)),\n",
        "        [tokenizer.decode(ids[ids != 0]) for ids in batch['input_ids']],\n",
        "        score):\n",
        "    print(text)\n",
        "\n",
        "    print('prediction: {:.2f}    truth: {:.2f}'.format(predicted_score.item(), true_score.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUVpV8MhvzUe"
      },
      "source": [
        "text1 = 'Hur öppnar jag outlook?'\n",
        "text2 = 'Hur öppnar jag min mail-klient?'\n",
        "\n",
        "with torch.no_grad():\n",
        "    print(model({k:v.cuda() for k, v in encode([text1], [text2]).items()}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuYkpzaI2h1T"
      },
      "source": [
        "# Namnigenkänning (Named Entity Recognition)\n",
        "\n",
        "Exempel: Namnigenkänning\n",
        "\n",
        "Kort förklaring av namnigenkänning\n",
        "\n",
        "BERT base fine-tuned for Swedish NER. This model is fine-tuned on the SUC 3.0 dataset.\n",
        "\n",
        "Entity types used are TME for time, PRS for personal names, LOC for locations, EVN for events and ORG for organisations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3utLAz92lLV"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLI4eQYm2mY7"
      },
      "source": [
        "nlp('Hej jag heter Bertil och jobbar på Trafikverket i Målilla och jag vill byta lösenord.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}