{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop squad sv.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekgren/workshop/blob/main/Day2/QA_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLDgGd-cvIJM"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rVaJCvku_ET"
      },
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import torch\n",
        "import copy\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu7XAwjgvCQP"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
        "kb_bert = transformers.AutoModel.from_pretrained('KB/bert-base-swedish-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwWKM13Bv8Qh"
      },
      "source": [
        "dataset = datasets.load_dataset('stsb_mt_sv')\n",
        "train_ds = dataset['train']\n",
        "test_ds = dataset['test']\n",
        "eval_ds = dataset['validation']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY7bY27Wz81V"
      },
      "source": [
        "def encode(*texts):\n",
        "  assert 1 <= len(texts) <= 2\n",
        "  return tokenizer(*texts, padding=True, truncation=True, max_length=512, return_tensors='pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K-oXDTY4Uw2"
      },
      "source": [
        "train_ds[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJaV1n6_zN-d"
      },
      "source": [
        "def collate_paired(rows):\n",
        "  s1s = [row['sentence1'] for row in rows]\n",
        "  s2s = [row['sentence2'] for row in rows]\n",
        "  scores = torch.tensor([row['score'] for row in rows])\n",
        "  return encode(s1s, s2s), scores\n",
        "\n",
        "def collate_dual(rows):\n",
        "  s1s = [row['sentence1'] for row in rows]\n",
        "  s2s = [row['sentence2'] for row in rows]\n",
        "  scores = torch.tensor([row['score'] for row in rows])\n",
        "  return encode(s1s), encode(s2s), scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjH8Eq1_1hE2"
      },
      "source": [
        "COLLATER = collate_paired\n",
        "train_dl = torch.utils.data.DataLoader(  \n",
        "    train_ds,\n",
        "    collate_fn=COLLATER,\n",
        "    shuffle=True,\n",
        "    batch_size=8,\n",
        "    pin_memory=True,\n",
        "  )\n",
        "test_dl = torch.utils.data.DataLoader(  \n",
        "    test_ds,\n",
        "    collate_fn=COLLATER,\n",
        "    shuffle=False,\n",
        "    batch_size=8,\n",
        "    pin_memory=True,\n",
        "  )\n",
        "eval_dl = torch.utils.data.DataLoader(  \n",
        "    eval_ds,\n",
        "    collate_fn=COLLATER,\n",
        "    shuffle=False,\n",
        "    batch_size=8,\n",
        "    pin_memory=True,\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSmDeCgx1von"
      },
      "source": [
        "\n",
        "class PairedModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = copy.deepcopy(kb_bert)\n",
        "    self.linear = torch.nn.Linear(768, 1)\n",
        "  \n",
        "  def forward(self, data):\n",
        "    return self.linear(self.model(**data)['pooler_output']).squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YfF9H7D8HPj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eViPm_oo8JM5"
      },
      "source": [
        "\n",
        "batch, score = next(iter(train_dl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH0s4FAkAZzC"
      },
      "source": [
        "\n",
        "paired_model(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmDAs9tD4mA-"
      },
      "source": [
        "paired_model = PairedModel().cuda()\n",
        "optimizer = torch.optim.AdamW(paired_model.parameters())\n",
        "EPOCHS = 1\n",
        "for epoch in range(EPOCHS):\n",
        "  batches = tqdm.tqdm(train_dl)\n",
        "  for batch, score in batches:\n",
        "    batch = {k : v.cuda() for k, v in batch.items()}\n",
        "    score = score.cuda()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    prediction = paired_model(batch)\n",
        "    \n",
        "    loss = torch.nn.functional.mse_loss(prediction, score)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    batches.set_description('{:.2f}'.format(loss.item()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0B_7TjI7fVq"
      },
      "source": [
        "# Exempel KB-Bert med ordmaskning\n",
        "\n",
        "När man förtränar Bert modeller så lär de sig språklig statistik genom att se massa text, maska ord och gissa vilket ord som bör vara på en den maskerade platsen. I slutändan är det nästan aldrig gissa ord som modellerna används till utan man anpassar (finetunear) dem till en annan uppgift. Men för att illustrera hur den förtränade modellen fungerar så gör vi en maskningsuppgift.\n",
        "\n",
        "Vi börjar med att ladda KB-Bert och dess tokeniserare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_0WDNy92X2F"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
        "model = transformers.BertForMaskedLM.from_pretrained('KB/bert-base-swedish-cased')\n",
        "print(type(model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou9eCXS93EuW"
      },
      "source": [
        "Vi hittar på en exempelmening."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_A_Ntyl2tV-"
      },
      "source": [
        "example = 'Hej och välkommen till Trafikverket! Myndigheten för dig som gillar vägar, bilar och tåg.'\n",
        "example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgMb_cAm5zkt"
      },
      "source": [
        "Bert är tränad med speciella ord i början och slutet av meningar, [CLS] och [SEP]. Modellen förutsätter att de är med när du stoppar in en mening. Om du skapar en batch med en huggingface tokeniserare görs detta automatiskt av tokeniseraren men i det här exemplet lägger vi till dem manuellt till exempelmeningen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YcMruOq8mUi"
      },
      "source": [
        "example_preprocessed = f'[CLS] {example} [SEP]'\n",
        "example_preprocessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra0PEXAHQ5bJ"
      },
      "source": [
        "Nu har vi vår mening i textform och nästa steg är att dela upp den i tokens med vår tokeniserare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMWJ1z2bxxIB"
      },
      "source": [
        "tokens = tokenizer.tokenize(example_preprocessed)\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEWij8oQRFuW"
      },
      "source": [
        "Sedan gör vi om våra tokens till index som modellen använder för att ta fram en sifferrepresentation av de tokens som går in i modellen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWpLDmHByA0L"
      },
      "source": [
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(indexed_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHTh_7PvRGIp"
      },
      "source": [
        "Nu till själva uppgiften som vi skall utföra med modellen. Vi väljer ut ett ord som ligger på plats 5 med nollindexering, \"Trafikverket\", och ersätter det med en [MASK] token. Detta för att sedan låta modellen givet resten av meningen gissa vilket ord som passar bäst in istället för [MASK]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF20g_vpyTa3"
      },
      "source": [
        "masked_index = 5\n",
        "tokens[masked_index] = '[MASK]'\n",
        "print(tokens)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"\\nToken index:\", indexed_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHCoN2fRRH5P"
      },
      "source": [
        "Sedan matar vi in vår exempelmening i KB-Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkiev0nNzT0I"
      },
      "source": [
        "_ = model.eval() # Sätter modellen i evalueringsläge för att spara minne. Då räknar den inte fram några gradienter.\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(torch.tensor([indexed_tokens]))\n",
        "\n",
        "predictions = outputs[0]\n",
        "print(predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Y9Q9MSzhQZ"
      },
      "source": [
        "predicted_index = torch.topk(predictions[0, masked_index], k=5)\n",
        "print(predicted_index.indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmOPOCzxzzXD"
      },
      "source": [
        "predicted_token = tokenizer.convert_ids_to_tokens(predicted_index.indices)\n",
        "print(predicted_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuYkpzaI2h1T"
      },
      "source": [
        "# Namnigenkänning (Named Entity Recognition)\n",
        "\n",
        "Exempel: Namnigenkänning\n",
        "\n",
        "Kort förklaring av namnigenkänning\n",
        "\n",
        "BERT base fine-tuned for Swedish NER. This model is fine-tuned on the SUC 3.0 dataset.\n",
        "\n",
        "Entity types used are TME for time, PRS for personal names, LOC for locations, EVN for events and ORG for organisations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3utLAz92lLV"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLI4eQYm2mY7"
      },
      "source": [
        "nlp('Hej jag heter Arne och jag vill byta lösenord.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYuCHsiC0Gbf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}