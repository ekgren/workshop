# Natural Language Understanding

## Quick ML Recap

## Distributional Hypothesis

### Cooc

### Word2Vec

## DH : Beyond the lexical level

### Bert

## Why pretraining? 

X is a necessary and sufficient to accomplish task A, B, C. 

If we train a model to accomplish task A, it should be able to accomplish task B. 

### Examples

- Document Classification
- Question Answering
- Semantic Similarity
- Machine Translation


